                        PROJETO INTEGRADOR IV - CURSO BIG DATA PARA NEGÓCIOS / FATEC IPIRANGA

-----------------------------------------------------------------------

                                        Cliente / Empresa:
                                                    
                        Razão Social: LUCIVAL ALVES DOS SANTOS 58387862568
                        Nome Fantasia: Translog Pombinha Branca
                        Porte: Microempresa
                        CNPJ: 09.446.165/0001-66
                        Data de Abertura: 06/05/2020 
                        Site (em construção): https://www.translogpombinhabranca.com/	
                        Responsável: Lúcio Santos
                        Email: lucio.santos@translogpombinhabranca.com
                        Atividade: Transporte Rodoviário de Carga
                                    
-----------------------------------------------------------------------                                
                                       DELTA LAKEHOUSE e DATA LAKE
                        
No projeto Translog Pombinha Branca, a escolha das ferramentas de
armazenamento e processamento de dados foi baseada em critérios como
escalabilidade, flexibilidade, custo-benefício e integração com tecnologias analíticas
modernas. A combinação de um Data Lake na AWS S3, um Data Lakehouse e a
plataforma Databricks oferece uma infraestrutura robusta para atender às necessidades
de coleta, organização, transformação e análise dos dados.

### **Arquitetura:**
A imagem anexada é uma representação arquitetural de um Data Lakehouse baseado no Databricks e Apache Spark, com integração ao Delta Lake para gerenciar dados de forma escalável e confiável. Vou detalhar os elementos presentes:

 

### **Ferramentas e Tecnologias Utilizadas:**

* Delta Lake: Gerencia a consistência dos dados através de versões e transações ACID, essencial para evitar problemas de concorrência e garantir integridade.

* Apache Spark: Responsável pelo processamento distribuído dos dados, possibilitando análises rápidas em grandes volumes.

* Databricks Workflows: Automatizam as tarefas de ingestão, transformação e geração de relatórios, garantindo que o pipeline funcione de ponta a ponta.

### **Workflow:**

<img align="center" src="https://github.com/WilPassion/ProjetoIntegrador4_FATEC/blob/main/imgs/workflow_upsell.PNG" alt="workflow-upsell" width="1000"> 
